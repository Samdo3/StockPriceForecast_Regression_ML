{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e36d072736d42b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T07:05:28.360887Z",
     "start_time": "2024-10-30T07:04:34.127890Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fimtrus/.pyenv/versions/openai/lib/python3.11/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.40.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0    \n",
      "{0: {'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': '', 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0 3   \n",
      "{0: {'sepal_length_cm': 3, 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': 3, 'sepal_width_cm': '', 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0 3 3  \n",
      "{0: {'sepal_length_cm': 3, 'sepal_width_cm': 3, 'petal_length_cm': '', 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': 3, 'sepal_width_cm': 3, 'petal_length_cm': '', 'petal_width_cm': ''}])\n",
      "0 3 3 3 \n",
      "{0: {'sepal_length_cm': 3, 'sepal_width_cm': 3, 'petal_length_cm': 3, 'petal_width_cm': ''}}\n",
      "dict_values([{'sepal_length_cm': 3, 'sepal_width_cm': 3, 'petal_length_cm': 3, 'petal_width_cm': ''}])\n",
      "0 3 3 3 3\n",
      "{0: {'sepal_length_cm': 3, 'sepal_width_cm': 3, 'petal_length_cm': 3, 'petal_width_cm': 3}}\n",
      "dict_values([{'sepal_length_cm': 3, 'sepal_width_cm': 3, 'petal_length_cm': 3, 'petal_width_cm': 3}])\n",
      "Keyboard interruption in main thread... closing server.\n",
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import gradio as gr\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#예측 진행\n",
    "def request_iris_prediction(data_list):\n",
    "    #ENDPOINT, METHOD, HEADER, BODY\n",
    "    endpoint = \"http://67688059-0432-4ea0-ba69-27cef7128005.koreacentral.azurecontainer.io/score\"\n",
    "    headers = {'Content-type': 'application/json',\n",
    "               'Authorization': 'Bearer xaFSLMfDUGyPCO5gV6pyseAUWNY9i0Ur'\n",
    "               }\n",
    "    body = {\n",
    "        \"Inputs\": {\n",
    "            \"input1\": data_list\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(endpoint, headers=headers, json=body)\n",
    "    print(response)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        result_list = response_json[\"Results\"][\"WebServiceOutput0\"]\n",
    "        return result_list\n",
    "    else:\n",
    "        return list()\n",
    "    \n",
    "def save_plot(data_points):\n",
    "    # 센터로이드의 평균 위치를 계산하기 위한 변수 초기화\n",
    "    centroid_positions = {0: [0, 0], 1: [0, 0], 2: [0, 0]}\n",
    "    centroid_colors = {0: 'b', 1: 'r', 2: 'g'}  # 클러스터 색상\n",
    "    \n",
    "    # 데이터 포인트를 기반으로 센터로이드 위치 계산\n",
    "    for point in data_points:\n",
    "        assignment = point[\"Assignments\"]\n",
    "    \n",
    "        # 각 클러스터별로 거리 데이터 가져오기\n",
    "        for i in range(3):\n",
    "            dist_key = f\"DistancesToClusterCenter no.{i}\"\n",
    "            if dist_key in point:\n",
    "                # 위치의 평균 계산\n",
    "                centroid_positions[i][0] += (point[\"sepal_length_cm\"] + point[dist_key]) / 2\n",
    "                centroid_positions[i][1] += (point[\"sepal_width_cm\"] + point[dist_key]) / 2\n",
    "    \n",
    "    # 평균값으로 센터로이드 위치 계산\n",
    "    for i in range(3):\n",
    "        centroid_positions[i][0] /= len(data_points)\n",
    "        centroid_positions[i][1] /= len(data_points)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    point_index = 0\n",
    "    # 데이터 포인트 그리기\n",
    "    for point in data_points:\n",
    "        point_index += 1\n",
    "        plt.scatter(point[\"sepal_length_cm\"], point[\"sepal_width_cm\"],\n",
    "                    c='b' if point[\"Assignments\"] == 0 else 'r' if point[\"Assignments\"] == 1 else 'g')\n",
    "        plt.text(point[\"sepal_length_cm\"], point[\"sepal_width_cm\"], f\"{point_index}\")\n",
    "\n",
    "    # 클러스터 센터로이드 그리기\n",
    "    for cluster, (x, y) in centroid_positions.items():\n",
    "        plt.scatter(x, y, c=centroid_colors[cluster], marker='X', s=200)\n",
    "\n",
    "    plt.title('Data Points and Cluster Centroids')\n",
    "    plt.xlabel('Sepal Length (cm)')\n",
    "    plt.ylabel('Sepal Width (cm)')\n",
    "    plt.grid()\n",
    "    plt.savefig('iris_clusters.png')\n",
    "    plt.close()  # plt.show() 대신 plt.close()를 사용\n",
    "    return 'iris_clusters.png'  # 현재 figure 반환\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    # 추가 버튼\n",
    "    def click_add(count):\n",
    "        print(\"click add\")\n",
    "        count += 1\n",
    "        return count\n",
    "\n",
    "    # 삭제 버튼\n",
    "    def click_delete(count):\n",
    "        if count > 1:\n",
    "            count -= 1\n",
    "        return count\n",
    "    \n",
    "    # 전송 버튼\n",
    "    def click_send():\n",
    "        # print(\"click send\")\n",
    "        # print(component_dict)\n",
    "        data_list = list(component_dict.values())\n",
    "        response_data = request_iris_prediction(data_list)\n",
    "        image_url = save_plot(response_data)\n",
    "        # return json.dumps(response_data, indent=3), image_url\n",
    "        return gr.Markdown(label=\"결과 데이터\", value=json.dumps(response_data, indent=3), visible=True), gr.Image(label=\"결과 이미지\", visible=True, value=image_url)\n",
    "        # return container\n",
    "    \n",
    "    # 데이터 입력시 이벤트    \n",
    "    def change_data(i, sl, sw, pl, pw):\n",
    "        global component_dict\n",
    "        component_dict.update({\n",
    "            i: {\n",
    "                \"sepal_length_cm\": sl,\n",
    "                \"sepal_width_cm\": sw,\n",
    "                \"petal_length_cm\": pl,\n",
    "                \"petal_width_cm\": pw\n",
    "            }\n",
    "        })\n",
    "        print(i, sl, sw, pl, pw)\n",
    "        print(component_dict)\n",
    "        print(component_dict.values())\n",
    "        # return i, sl, sw, pl, pw\n",
    "    \n",
    "    def add_component(count):\n",
    "        with gr.Group():\n",
    "            gr.Markdown(f'#### &emsp;{count + 1}')\n",
    "            with gr.Row():\n",
    "                row_index = gr.State(count)\n",
    "                sepal_length_number = gr.Number(label=\"꽃받침 길이\", key=f\"sepal-length-{count}\", value=\"\")\n",
    "                sepal_width_number = gr.Number(label=\"꽃받침 너비\", key=f\"sepal-width-{count}\", value=\"\")\n",
    "                petal_length_number = gr.Number(label=\"꽃잎 길이\", key=f\"petal-length-{count}\", value=\"\")\n",
    "                petal_width_number = gr.Number(label=\"꽃잎 너비\", key=f\"petal-width-{count}\", value=\"\")\n",
    "                \n",
    "                sepal_length_number.change(fn=change_data, inputs=[row_index, sepal_length_number, sepal_width_number, petal_length_number, petal_width_number], outputs=[])\n",
    "                \n",
    "                sepal_width_number.change(fn=change_data, inputs=[row_index, sepal_length_number, sepal_width_number, petal_length_number, petal_width_number], outputs=[])\n",
    "                \n",
    "                petal_length_number.change(fn=change_data, inputs=[row_index, sepal_length_number, sepal_width_number, petal_length_number, petal_width_number], outputs=[])\n",
    "                \n",
    "                petal_width_number.change(fn=change_data, inputs=[row_index, sepal_length_number, sepal_width_number, petal_length_number, petal_width_number], outputs=[])\n",
    "    \n",
    "    view_count = gr.State(1)\n",
    "    component_dict = dict()\n",
    "    # input_list = gr.State(list())\n",
    "    gr.Markdown(f'### 붓꽃 예측')\n",
    "    gr.Markdown(f'#### sepal : 꽃받침, petal: 꽃잎')\n",
    "    gr.Markdown(f'#### 6, 4, 2, 3 | 4.8, 3.4, 1.6, 0.2 | 4.8, 3.4, 1.4, 0.1 | 4.3, 3, 1.1, 0.1  ')\n",
    "    \n",
    "    with gr.Row():\n",
    "        add_button = gr.Button(\"+\")\n",
    "        delete_button = gr.Button(\"-\")\n",
    "        \n",
    "    with gr.Column():\n",
    "        @gr.render(inputs=[view_count])\n",
    "        def render_input_components(count):\n",
    "            for i in range(0, count):\n",
    "               add_component(i)\n",
    "                \n",
    "    send_button = gr.Button(\"전송\")\n",
    "    response_markdown = gr.Markdown(label=\"결과\", visible=False)\n",
    "    response_plot = gr.Image(label=\"결과 차트\", type=\"filepath\", visible=False)\n",
    "    \n",
    "    add_button.click(fn=click_add, inputs=[view_count], outputs=[view_count])\n",
    "    delete_button.click(fn=click_delete, inputs=[view_count], outputs=[view_count])\n",
    "    send_button.click(fn=click_send, inputs=[], outputs=[response_markdown, response_plot])\n",
    "    \n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f79834bbaa331",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Open', 'High', 'Low', 'Close', 'Volume'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m stock_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#Nasdaq 데이터 전처리\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m global_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOpen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHigh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVolume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#AAPL, Nasdaq merge\u001b[39;00m\n\u001b[0;32m     38\u001b[0m stock_merge_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(stock_data, global_data, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\clcle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clcle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\clcle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\clcle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Open', 'High', 'Low', 'Close', 'Volume'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import yfinance as yf \n",
    "import pandas as pd\n",
    "\n",
    "ticker=[\"TSLA\",\"AAPL\",\"NVDA\",\"MSFT\",\"GOOGL\"]\n",
    "    #나스닥 파일 불러오기\n",
    "data_path = 'data/nasdq_20241106.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "    \n",
    "start_date = '2010-01-04'\n",
    "end_date = '2024-11-06'\n",
    "\n",
    "for i in ticker:\n",
    "    stock_data = yf.download(i, start=start_date, end=end_date)\n",
    "    \n",
    "    #AAPL 데이터 전처리\n",
    "    stock_data.reset_index(inplace=True)\n",
    "    stock_data['Date'] = stock_data['Date'].dt.strftime('%Y-%m-%d')\n",
    "    stock_data.columns = ['Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    stock_data.drop(columns=['Adj Close'], inplace=True)\n",
    "    \n",
    "    #Nasdaq 데이터 전처리\n",
    "    #global_data = data.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "\n",
    "    #AAPL, Nasdaq merge\n",
    "    stock_merge_data = pd.merge(stock_data, data, on='Date', how='inner')\n",
    "\n",
    "    #merge data 전처리\n",
    "    stock_merge_data['Date'] = pd.to_datetime(stock_merge_data['Date'])\n",
    "    stock_merge_data.set_index('Date', inplace=True)\n",
    "    stock_merge_data.columns = stock_merge_data.columns.str.replace(' ', '')\n",
    "\n",
    "    stock_merge_data['Close_InterestRate_Corr'] = stock_merge_data['Close'].rolling(252).corr(stock_merge_data['InterestRate'])\n",
    "    stock_merge_data['Close_VIX_Corr'] = stock_merge_data['Close'].rolling(252).corr(stock_merge_data['VIX'])\n",
    "    stock_merge_data['Rolling_Volatility'] = stock_merge_data['Close'].rolling(window=30).std()\n",
    "\n",
    "    stock_merge_data['Daily_Return'] = stock_merge_data['Close'].pct_change()\n",
    "    stock_merge_data['Volatility'] = stock_merge_data['Close'].rolling(window=30).std() # 이동 표준 편차를 계산하라\n",
    "    stock_merge_data['Rolling_Mean_Close'] = stock_merge_data['Close'].rolling(window=30).mean()\n",
    "    stock_merge_data.dropna(inplace=True)\n",
    "    \n",
    "    # Step 1: Replace infinite values with NaN\n",
    "    stock_merge_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Step 2: Check for NaN values and handle them\n",
    "    # Using forward fill to handle NaN values (you can adjust this as needed)\n",
    "    stock_merge_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 데이터 저장\n",
    "    #save_path = f\"{i}.csv\"\n",
    "    #stock_merge_data.to_csv(save_path)\n",
    "    print(stock_merge_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89990875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

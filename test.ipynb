{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2016-10-06     28.472500\n",
       "2011-03-16     11.786071\n",
       "2013-04-05     15.114286\n",
       "2017-05-30     38.417500\n",
       "2015-08-18     29.125000\n",
       "                 ...    \n",
       "2022-05-12    142.559998\n",
       "2013-04-25     14.585000\n",
       "2021-06-02    125.059998\n",
       "2021-07-19    142.449997\n",
       "2011-04-15     11.695000\n",
       "Name: Close, Length: 691, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import yfinance as yf \n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "ticker=\"AAPL\"\n",
    "    \n",
    "    #나스닥 파일 불러오기\n",
    "data_path = 'data/nasdq_20241104.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "    \n",
    "start_date = '2010-01-04'\n",
    "end_date = '2024-10-25'\n",
    "stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    #AAPL 데이터 전처리\n",
    "stock_data.reset_index(inplace=True)\n",
    "stock_data['Date'] = stock_data['Date'].dt.strftime('%Y-%m-%d')\n",
    "stock_data.columns = ['Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
    "stock_data.drop(columns=['Adj Close'], inplace=True)\n",
    "    \n",
    "    #Nasdaq 데이터 전처리\n",
    "#global_data = data.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "\n",
    "    #AAPL, Nasdaq merge\n",
    "stock_merge_data = pd.merge(stock_data, data, on='Date', how='inner')\n",
    "\n",
    "    #merge data 전처리\n",
    "stock_merge_data['Date'] = pd.to_datetime(stock_merge_data['Date'])\n",
    "stock_merge_data.set_index('Date', inplace=True)\n",
    "stock_merge_data.columns = stock_merge_data.columns.str.replace(' ', '')\n",
    "\n",
    "stock_merge_data['Close_InterestRate_Corr'] = stock_merge_data['Close'].rolling(252).corr(stock_merge_data['InterestRate'])\n",
    "stock_merge_data['Close_VIX_Corr'] = stock_merge_data['Close'].rolling(252).corr(stock_merge_data['VIX'])\n",
    "stock_merge_data['Rolling_Volatility'] = stock_merge_data['Close'].rolling(window=30).std()\n",
    "\n",
    "stock_merge_data['Daily_Return'] = stock_merge_data['Close'].pct_change()\n",
    "stock_merge_data['Volatility'] = stock_merge_data['Close'].rolling(window=30).std() # 이동 표준 편차를 계산하라\n",
    "stock_merge_data['Rolling_Mean_Close'] = stock_merge_data['Close'].rolling(window=30).mean()\n",
    "stock_merge_data.dropna(inplace=True)\n",
    "\n",
    "stock_merge_data_head = stock_merge_data.iloc[:-10] # 앞쪽 \n",
    "stock_merge_data_tail = stock_merge_data.iloc[-10:] # 뒷쪽 10개\n",
    "    \n",
    "\n",
    "X = stock_merge_data_head.drop(['Close', 'High', 'Low', 'Volume'], axis=1)  # Ensure 'Close' is dropped to create the feature set\n",
    "y = stock_merge_data_head['Close']  # Target variable is 'Close' price\n",
    "\n",
    "\n",
    "\n",
    "    # Step 1: Replace infinite values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Step 2: Check for NaN values and handle them\n",
    "    # Using forward fill to handle NaN values (you can adjust this as needed)\n",
    "X.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Step 3: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "    # Step 4: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "   # Initialize and train a random forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "ser_rf=pd.Series(y_pred_rf)\n",
    "\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       28.570100\n",
       "1       12.216068\n",
       "2       15.255550\n",
       "3       38.297674\n",
       "4       28.834525\n",
       "          ...    \n",
       "686    140.377602\n",
       "687     14.972096\n",
       "688    125.005400\n",
       "689    141.023901\n",
       "690     11.934375\n",
       "Length: 691, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_rf=pd.Series(y_pred_rf)\n",
    "ser_rf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
